{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhD Seminar Course on advanced Artificial Intelligence algorithms \n",
    "# by Dr. Paul Rad @ UT San Antonio.\n",
    "# Assignment-1 \n",
    "# CNN Rotation Invariance Project\n",
    "Students: Mehrad Jaloli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariance means that you can recognize an object as an object, even when its appearance varies in some way. This is generally a good thing, because it preserves the object's identity, category, (etc) across changes in the specifics of the visual input, like relative positions of the viewer/camera and the object.\n",
    "Figure 1 contains many views of the same statue. You (and well-trained neural networks) can recognize that the same object appears in every picture, even though the actual pixel values are quite different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN Model\n",
    "Convolutional Neural Network (CNN) is a deep model working based on convolution concept. CNN is constructed of some convolution and max-pooling layers, called feature extraction part, and some fully connected layers which is the classification part. \n",
    "The whole idea of training in CNN model is while feeding images to the network, we have some kernels acting like filters. These kernels slide all over the images and do some filtering function based on which some features are extracted from the images. So, the output of each convolution layer would be some feature maps.\n",
    "\n",
    "Based on the complexity of the problem and data set that we are using, the depth of the model (number of the layers) could be different. The more complex our model is, the more convolution layers we need for having a better feature extraction. \n",
    "\n",
    "One of the main concerns in using CNN models in real life is if those models can keep their performance well even while input images have some transformations, like rotation. So, we went through this concept and tried to solve one of the translation problems, \"Rotation Invariance\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/invar1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Invariance vs Equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation invariance means that the system produces exactly the same response, regardless of how its input is shifted. For example, a face-detector might report \"FACE FOUND\" for all three images in the top row.\n",
    " Equivariance means that the system works equally well across positions, but its response shifts with the position of the target. For example, a heat map of \"face-iness\" would have similar bumps at the left, center, and right when it processes the first row of images.\n",
    "\n",
    "This is is sometimes an important distinction, but many people call both phenomena \"invariance\", especially since it is usually trivial to convert an equivariant response into an invariant one--just disregard all the position information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Rotation Invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on section 2, we try to define rotation invariance and tied to solve it.\n",
    "\n",
    "The procedure has been using the MNIST data set, feeding it into the model LeNet5, which is one of the well-known CNN model for image classification problem, training the model with the original data and then test the model with rotated images. Our purpose is to see whether the model can have an acceptable performance in classifying these rotated images as test data or not.\n",
    "\n",
    "So, to go through this problem, firstly, we try to give a brief description about how each layer works in CNN model and how the layers are connected to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 CNN Opperation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we are using MNIST data set which are images of gray handwritten digits with the size 28*28*1 (1 is the number of color channel which for gray is equal to 1). \n",
    "\n",
    "Once we feed the data into a convolution layer, there would be a kernel of size 5*5 (in LeNet-5 model)sliding all along the image and corresponds each block of 5 by 5 pixels of the original image to 1 pixel in the output of the first conv layer.\n",
    "\n",
    "The output of each conv layer will be K images of size (Ns-Ks+1)*(Ns-Ks+1), while Ns*Ns is the size of original images fed to the model, Ks is the size of the kernel used for the conv layer and K is the number of kernels. Notice that each one of the images at the output of the conv layer are called feature map. \n",
    "Down Sampling} or reducing the computational cost. Here we should note that in this code we are applying kernels with stride=2, so it affects the size of the out put feature map.\n",
    "\n",
    "By using a pooling layer of size 2*2 we are actually dividing the size of feature maps by 2. So, considering the MNIST dataset, after using \\textbf{6} kernels of size 5*5 with stride=2 for the first conv layer we will have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                   6*(32-5+1)*(32-5+1) = 6*28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then by applying a pooling layer of size 2*2 we will have,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                              size of the images after pooling layer = 6*14*14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have different pooling layers. Maxpooling, takes the maximum value between the pixels that pooling block is applied while Average pooling takes the average of all the pixels the pooling block is applied.\n",
    "Max pooling extracts the most important features like edges whereas, average pooling extracts features so smoothly. For image data, you can see the difference. Although both are used for same reason, max pooling is better for extracting the extreme features. Average pooling sometimes canâ€™t extract good features because it takes all into count and results an average value which may/may not be important for object detection type tasks.\n",
    "It should be noted that the whole purpose of the convolution and pooling layers is feature extraction. \n",
    "After 3 convolution and 2 maxpooling layers in LeNet5 (feature extractor part of the CNN) we will get to the dimension, 120*7*7. Then we will have some \\textbf{Fully Connected} layers. \n",
    "The purpose of fully connected layers are Classification. So, we use a Flatten Layer and transform the images to a vector (which in LeNet-5 is a vector of size 120).\n",
    "Then we use Fully Connected layers of size 84 and 10 respectively, and based on machine learning algorithms, specifically classification algorithms, we classify the images in 10 classes (digits from 0 to 9). \n",
    "So, for the outermost layer we use a Soft Max layer which takes output of the last Fully Connected layer (which is a vector of size 1*10) and results 10 neurons as output corresponding to 10 classes (digits from 0 to 9).\n",
    "\n",
    "The cost function used in LeNet-5 model is Cross-Entropy the outputs of which are probabilities.\n",
    "Below in figure 2, you can see the architecture of LeNet-5 model.\n",
    "Furthermore, the detailed architecture of Lenet-5 model based on the layers would be like figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization of Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if the CNN model is Rotation Invariance or not, we should be able to visualize the out put of each layer to see the changes after each conv layer. \n",
    "\n",
    "In figure 4 we can visualize the kernels of the first convolution layer, which are actually the weights we want to obtain after training the model.\n",
    "\n",
    "Moreover, I have also attached the output of the 2nd and 3rd convolution layer in appendix on figure 7 and 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a better understanding of what visualization means, we choose one of the images from data set and feed it to the model. Then we look at the output of each convolution layer to see how the model actually comes up with prediction of mentioned digit. \n",
    "\n",
    "As an instance, we feed one of the images which is the handwritten of digit 4. As we go through the model, we can see the process in which model can identify the actual digit written in the picture.  \n",
    "\n",
    "Figure 5 represents the images obtained from out put of the first convolution layer which we call Feature Maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, based on the architecture we have selected for our model, we have 6 feature maps at the out put of the first convolution layer so on figure 5, we see the out pt of each activation function applied to each feature map.\n",
    "\n",
    "we can have this visualization for the other convolution layers as it is shown on figures 9 and 10 in appendix section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, the goal of this project was investigating CNN model to see if it is Rotation Invariant or not. For this, we use visualization and try to go through the out put of each layer.\n",
    "\n",
    "Thus, we define a function that gets images and rotate them by some specific degrees. In the code, this  function is called, \"\\textbf{rotate\\_tensor}. Using this function, we rotate an image (one image of label 4) by 90, 180 and 270 degrees, as shown in figure 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For investigating the Rotation Invariance property of LeNet5, we use the pre-trained model with original MNIST dataset, then we test our rotated data sets to see the accuracy of the model.\n",
    "Below, in table 1, you can see the results of training and testing LeNet-5 with the original MNIST data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/tab1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, in table 2 we can see the results obtained from testing the pre-trained LeNet5 model with images rotated by 90, 180, 270 and 360 degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/tab2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, we have tested with 360 degree rotated images to see if it gives the same results as the original MNIST data set or not. As we can see, based on table 1 and 2, the test accuracy for these 2 data sets are the same, proving that our function (rotate\\_tensor) works properly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Concolusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this problem in to perspective, we can say that the CNN models are \\textbf{not Rotation Invariant} since as it is represented in the previous section, if the model is trained with a certain data set, it can not give a good accuracy on rotated images from the same data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig89.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go though the codes to see the whole process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "kwargs={}\n",
    "args['batch_size']=1000\n",
    "args['test_batch_size']=1000\n",
    "args['epochs']=20  # The number of Epochs is the number of times you go \n",
    "                   # through the full dataset. \n",
    "args['lr']=0.01 # Learning rate is how fast it will decend. \n",
    "args['momentum']=0.5 # SGD momentum (default: 0.5) Momentum is a moving \n",
    "                     # average of our gradients (helps to keep direction).\n",
    "\n",
    "args['seed']=1 # random seed\n",
    "args['log_interval']=40\n",
    "args['cuda']=True # False if you don't have a CUDA w/ NVIDIA GPU available.\n",
    "args['train_now']=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Rotation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRotation(object):\n",
    "    \"\"\"Rotate image by a fixed angle which is ready for tranform.Compose()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        self.degrees = degrees\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        return transforms.ToTensor()(\n",
    "            transforms.functional.rotate(\n",
    "                transforms.ToPILImage()(img), \n",
    "                self.degrees, self.resample, self.expand, self.center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = 0 # Specifies the rotation of images.\n",
    "\n",
    "# Define the train and test loader\n",
    "# Here we are adding our CustomRotation function to the transformations\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):          \n",
    "     \n",
    "    def __init__(self):     \n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolution (In LeNet-5, 32x32 images are given \n",
    "        # as input. Hence padding of 2 is done below)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, \n",
    "                                     kernel_size=5, stride=1, padding=2)\n",
    "        self.max_pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, \n",
    "                                     kernel_size=5, stride=1, padding=2)\n",
    "        self.max_pool_2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, \n",
    "                                     kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(7*7*120, 120)\n",
    "        # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
    "        self.fc2 = nn.Linear(120, 84)       \n",
    "        # convert matrix with 120 features to a matrix of 84 features (columns)\n",
    "        self.fc3 = nn.Linear(84, 10)        \n",
    "        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        # max-pooling with 2x2 grid \n",
    "        x = self.max_pool_1(x) \n",
    "        # Conv2 + ReLU\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_2(x)\n",
    "        # Conv3 + ReLU\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 7*7*120)\n",
    "        # FC-1, then perform ReLU non-linearity\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # FC-2, then perform ReLU non-linearity\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # FC-3\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()\n",
    "if args['cuda']:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        #Variables in Pytorch are differenciable. \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #This will zero out the gradients for this batch. \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # Calculate the loss The negative log likelihood loss. \n",
    "        # It is useful to train a classification problem with C classes.\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #dloss/dx for every Variable \n",
    "        loss.backward()\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss # size_average and reduce args will \n",
    "        # be deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "##test with 90 degree rotated images\n",
    "# ##=====\n",
    "# rotation=90\n",
    "# test_loader_90 = torch.utils.data.DataLoader(\n",
    "# datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     CustomRotation(rotation),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])),\n",
    "#     batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n",
    "\n",
    "# def test_90():\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader_90:\n",
    "#         if args['cuda']:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         with torch.no_grad(): # volatile was removed and now \n",
    "#             # has no effect. Use `with torch.no_grad():` instead.\n",
    "#             data= Variable(data)\n",
    "#         target = Variable(target)\n",
    "#         output = model(data)\n",
    "#         # sum up batch loss # size_average and reduce args will be \n",
    "#         # deprecated, please use reduction='sum' instead.\n",
    "#         test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "#         # get the index of the max log-probability\n",
    "#         pred = output.data.max(1, keepdim=True)[1] \n",
    "#         correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "#     test_loss /= len(test_loader_90.dataset)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader_90.dataset),\n",
    "#         100. * correct / len(test_loader_90.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "# Training loop. \n",
    "# Change `args['log_interval']` if you want to change logging behavior.\n",
    "# We test the network in each epoch.\n",
    "# Setting the bool `args['train_now']` to not run training all the time.\n",
    "# We'll save the weights and use the saved weights instead of \n",
    "# training the network everytime we load the jupyter notebook.\n",
    "args['train_now'] = True\n",
    "args['cuda'] = True\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    torch.save(model.state_dict(), './model_normal_mnist.pytrh')\n",
    "else:\n",
    "    model = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "    model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_viz(kernels, path=None, cols=None):\n",
    "    \"\"\"Visualize weight and activation matrices learned \n",
    "    during the optimization process. Works for any size of kernels.\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    kernels: Weight or activation matrix. Must be a high dimensional\n",
    "    Numpy array. Tensors will not work.\n",
    "    path: Path to save the visualizations.\n",
    "    cols: TODO: Number of columns (doesn't work completely yet.)\n",
    "    \n",
    "    Example\n",
    "    =======\n",
    "    kernels = model.conv1.weight.cpu().detach().clone()\n",
    "    kernels = kernels - kernels.min()\n",
    "    kernels = kernels / kernels.max()\n",
    "    custom_viz(kernels, 'results/conv1_weights.png', 5)\n",
    "    \"\"\"\n",
    "    def set_size(w,h, ax=None):\n",
    "        \"\"\" w, h: width, height in inches \"\"\"\n",
    "        if not ax: ax=plt.gca()\n",
    "        l = ax.figure.subplotpars.left\n",
    "        r = ax.figure.subplotpars.right\n",
    "        t = ax.figure.subplotpars.top\n",
    "        b = ax.figure.subplotpars.bottom\n",
    "        figw = float(w)/(r-l)\n",
    "        figh = float(h)/(t-b)\n",
    "        ax.figure.set_size_inches(figw, figh)\n",
    "    \n",
    "    N = kernels.shape[0]\n",
    "    C = kernels.shape[1]\n",
    "\n",
    "    Tot = N*C\n",
    "\n",
    "    # If single channel kernel with HxW size,\n",
    "    # plot them in a row.\n",
    "    # Else, plot image with C number of columns.\n",
    "    if C>1:\n",
    "        columns = C\n",
    "    elif cols==None:\n",
    "        columns = N\n",
    "    elif cols:\n",
    "        columns = cols\n",
    "    rows = Tot // columns \n",
    "    rows += Tot % columns\n",
    "\n",
    "    pos = range(1,Tot + 1)\n",
    "    fig = plt.figure(1)\n",
    "    fig.tight_layout()\n",
    "    k=0\n",
    "    for i in range(kernels.shape[0]):\n",
    "        for j in range(kernels.shape[1]):\n",
    "            img = kernels[i][j]\n",
    "            ax = fig.add_subplot(rows,columns,pos[k])\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            k = k+1\n",
    "\n",
    "    set_size(30,30,ax)\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=100)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = model.conv1.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv1_weights.png', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = model.conv2.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv2_weights.png', cols=5)\n",
    "kernels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = model.conv3.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv3_weights.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_tensor(_in_tensor, plot=True):\n",
    "    in_tensor = _in_tensor.clone()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,1,28,28\n",
    "    in_tensor.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    in_tensor = Variable(in_tensor, requires_grad=True)\n",
    "    \n",
    "    in_tensor_90 = in_tensor.transpose(2, 3).flip(3)\n",
    "    in_tensor_180 = in_tensor.flip(2).flip(3)\n",
    "    in_tensor_270 = in_tensor.transpose(2, 3).flip(2)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(221)\n",
    "        plt.gca().set_title('0 degree')\n",
    "        plt.imshow(in_tensor[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(222)\n",
    "        plt.gca().set_title('+90 degree')\n",
    "        plt.imshow(in_tensor_90[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(223)\n",
    "        plt.gca().set_title('+270 degree')\n",
    "        plt.imshow(in_tensor_270[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.subplot(224)\n",
    "        plt.gca().set_title('+180 degree')\n",
    "        plt.imshow(in_tensor_180[0][0].cpu().detach().clone(), cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return(in_tensor, in_tensor_90, in_tensor_180, in_tensor_270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number, number_90, number_180, number_270 = rotate_tensor(example_data[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted Class: \", \n",
    "      np.argmax(model.forward(number.cuda()).cpu().detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out = model.conv1.forward(number.cuda())\n",
    "\n",
    "custom_viz(conv1_out.cpu().detach().clone(), './results/conv1_actv.png')\n",
    "conv1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_out = model.conv2.forward(conv1_out.cuda())\n",
    "custom_viz(conv2_out.cpu().detach().clone(), './results/conv2_actv.png')\n",
    "conv2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out = model.conv3.forward(conv2_out.cuda())\n",
    "custom_viz(conv3_out.cpu().detach().clone(), './results/conv3_actv.png')\n",
    "conv3_out.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv4_out = model.conv4.forward(conv3_out.cuda())\n",
    "custom_viz(conv4_out.cpu().detach().clone(), './conv4_actv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the rotation\n",
    "rotation = 90\n",
    "\n",
    "# Load the data\n",
    "train_loader_90 = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), \n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "test_loader_90 = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    CustomRotation(rotation),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n",
    "\n",
    "# Get some example data from test loader\n",
    "examples_90 = enumerate(test_loader_90)\n",
    "batch_idx, (example_data_90, example_targets_90) = next(examples_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify and account for GPU usage\n",
    "model_90 = LeNet5()\n",
    "if args['cuda']:\n",
    "    model_90.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with 90 degree rotation MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test functions as before. \n",
    "# TODO: Consider adding model as an argument.\n",
    "\n",
    "def train_90(epoch):\n",
    "    model_90.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader_90):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        #Variables in Pytorch are differenciable. \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #This will zero out the gradients for this batch. \n",
    "        optimizer.zero_grad()\n",
    "        output = model_90(data)\n",
    "        # Calculate the loss The negative log likelihood loss. \n",
    "        # It is useful to train a classification problem with C classes.\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #dloss/dx for every Variable \n",
    "        loss.backward()\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_90.dataset),\n",
    "                100. * batch_idx / len(train_loader_90), loss.data))\n",
    "\n",
    "def test_90():\n",
    "    model_90.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader_90:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model_90(data)\n",
    "        # sum up batch loss # size_average and reduce args will be \n",
    "        # deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader_90.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_90.dataset),\n",
    "        100. * correct / len(test_loader_90.dataset)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and train the model.\n",
    "# If the model is already trained, try to load the model.\n",
    "# Will give an error if trained model doesn't exist.\n",
    "\n",
    "optimizer = optim.SGD(model_90.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train_90(epoch)\n",
    "        test_90()\n",
    "    torch.save(model_90.state_dict(), './model_90_mnist.pytrh')\n",
    "else:\n",
    "    model_90 = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model_90.load_state_dict(torch.load('./model_90_mnist.pytrh'))\n",
    "        model_90.to(device)\n",
    "    else:\n",
    "        model_90.load_state_dict(torch.load('./model_90_mnist.pytrh'))\n",
    "    model_90.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = model_90.conv1.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv1_weights_90.png', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = model_90.conv2.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv2_weights_90.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = model_90.conv3.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv3_weights_90.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels = model.conv4.weight.cpu().detach().clone()\n",
    "kernels = kernels - kernels.min()\n",
    "kernels = kernels / kernels.max()\n",
    "custom_viz(kernels, './results/conv4_weights_90.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted Class: \", \n",
    "      np.argmax(model_90.forward(number_90.cuda()).cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out_90 = model_90.conv1.forward(number_90.cuda())\n",
    "custom_viz(conv1_out_90.cpu().detach().clone(), 'results/conv1_actv_90.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv2_out_90 = model_90.conv2.forward(conv1_out_90.cuda())\n",
    "custom_viz(conv2_out_90.cpu().detach().clone(), 'results/conv2_actv_90.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out_90 = model_90.conv3.forward(conv2_out_90.cuda())\n",
    "custom_viz(conv3_out_90.cpu().detach().clone(), 'results/conv3_actv_90.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv4_out_90 = model_90.conv4.forward(conv3_out_90.cuda())\n",
    "custom_viz(conv4_out_90.cpu().detach().clone(), 'results/conv4_actv_90.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Original LeNet5 model with 90 degree rotated test dataset from MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if args['cuda']:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         #Variables in Pytorch are differenciable. \n",
    "#         data, target = Variable(data), Variable(target)\n",
    "#         #This will zero out the gradients for this batch. \n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         # Calculate the loss The negative log likelihood loss. \n",
    "#         # It is useful to train a classification problem with C classes.\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         #dloss/dx for every Variable \n",
    "#         loss.backward()\n",
    "#         #to do a one-step update on our parameter.\n",
    "#         optimizer.step()\n",
    "#         #Print out the loss periodically. \n",
    "#         if batch_idx % args['log_interval'] == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.data))\n",
    "\n",
    "def test_90():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader_90:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss # size_average and reduce args will be \n",
    "        # deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader_90.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_90.dataset),\n",
    "        100. * correct / len(test_loader_90.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "# Training loop. \n",
    "# Change `args['log_interval']` if you want to change logging behavior.\n",
    "# We test the network in each epoch.\n",
    "# Setting the bool `args['train_now']` to not run training all the time.\n",
    "# We'll save the weights and use the saved weights instead of \n",
    "# training the network everytime we load the jupyter notebook.\n",
    "args['train_now'] = False\n",
    "args['cuda'] = True\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    torch.save(model.state_dict(), './model_normal_mnist.pytrh')\n",
    "else:\n",
    "    model = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_90()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Original LeNet5 model with 180 degree rotated test dataset from MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the rotation\n",
    "rotation = 180\n",
    "\n",
    "# Load the data\n",
    "train_loader_180 = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), \n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "test_loader_180 = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    CustomRotation(rotation),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n",
    "\n",
    "# Get some example data from test loader\n",
    "examples_180 = enumerate(test_loader_180)\n",
    "batch_idx, (example_data_180, example_targets_180) = next(examples_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_180():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader_180:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss # size_average and reduce args will be \n",
    "        # deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader_180.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_180.dataset),\n",
    "        100. * correct / len(test_loader_180.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "# Training loop. \n",
    "# Change `args['log_interval']` if you want to change logging behavior.\n",
    "# We test the network in each epoch.\n",
    "# Setting the bool `args['train_now']` to not run training all the time.\n",
    "# We'll save the weights and use the saved weights instead of \n",
    "# training the network everytime we load the jupyter notebook.\n",
    "args['train_now'] = False\n",
    "args['cuda'] = True\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    torch.save(model.state_dict(), './model_normal_mnist.pytrh')\n",
    "else:\n",
    "    model = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_180()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Original LeNet5 model with 270 degree rotated test dataset from MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the rotation\n",
    "rotation = 270\n",
    "\n",
    "# Load the data\n",
    "train_loader_270 = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), \n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "test_loader_270 = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    CustomRotation(rotation),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n",
    "\n",
    "# Get some example data from test loader\n",
    "examples_270 = enumerate(test_loader_270)\n",
    "batch_idx, (example_data_270, example_targets_270) = next(examples_270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_270():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader_270:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss # size_average and reduce args will be \n",
    "        # deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader_270.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_270.dataset),\n",
    "        100. * correct / len(test_loader_270.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "# Training loop. \n",
    "# Change `args['log_interval']` if you want to change logging behavior.\n",
    "# We test the network in each epoch.\n",
    "# Setting the bool `args['train_now']` to not run training all the time.\n",
    "# We'll save the weights and use the saved weights instead of \n",
    "# training the network everytime we load the jupyter notebook.\n",
    "args['train_now'] = False\n",
    "args['cuda'] = True\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    torch.save(model.state_dict(), './model_normal_mnist.pytrh')\n",
    "else:\n",
    "    model = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_270()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Original LeNet5 model with 360 degree rotated test dataset from MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the rotation\n",
    "rotation = 360\n",
    "\n",
    "# Load the data\n",
    "train_loader_360 = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), \n",
    "                       CustomRotation(rotation),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "test_loader_360 = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('data/', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    CustomRotation(rotation),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False, **kwargs)\n",
    "\n",
    "# Get some example data from test loader\n",
    "examples_360 = enumerate(test_loader_360)\n",
    "batch_idx, (example_data_360, example_targets_360) = next(examples_360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_360():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader_360:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad(): # volatile was removed and now \n",
    "            # has no effect. Use `with torch.no_grad():` instead.\n",
    "            data= Variable(data)\n",
    "        target = Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss # size_average and reduce args will be \n",
    "        # deprecated, please use reduction='sum' instead.\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').data \n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader_360.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_360.dataset),\n",
    "        100. * correct / len(test_loader_360.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args['lr'], momentum=args['momentum'])\n",
    "\n",
    "# Training loop. \n",
    "# Change `args['log_interval']` if you want to change logging behavior.\n",
    "# We test the network in each epoch.\n",
    "# Setting the bool `args['train_now']` to not run training all the time.\n",
    "# We'll save the weights and use the saved weights instead of \n",
    "# training the network everytime we load the jupyter notebook.\n",
    "args['train_now'] = False\n",
    "args['cuda'] = True\n",
    "\n",
    "if args['train_now']:\n",
    "    for epoch in range(1, args['epochs'] + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    torch.save(model.state_dict(), './model_normal_mnist.pytrh')\n",
    "else:\n",
    "    model = LeNet5()\n",
    "    if args['cuda']:\n",
    "        device = torch.device(\"cuda\")\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('./model_normal_mnist.pytrh'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_360()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
